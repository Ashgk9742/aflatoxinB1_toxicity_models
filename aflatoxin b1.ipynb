{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Compile a list of differentially expressed genes (DEGs) from your GEO2R dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file GSE127791.top.table.tsv: \"['Gene.symbol'] not in index\"\n",
      "Error processing file GSE153590.top.table.tsv: \"['Gene.symbol'] not in index\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agk78\\AppData\\Local\\Temp\\ipykernel_5008\\3944322657.py:27: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  compiled_data = pd.concat([compiled_data, data], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file GSE40117.top.table.tsv: \"['Gene.symbol'] not in index\"\n",
      "Error processing file GSE51175.top.table.tsv: \"['Gene.symbol'] not in index\"\n",
      "Error processing file GSE57132.top.table (1).tsv: \"['Gene.symbol'] not in index\"\n",
      "Error processing file GSE57132.top.table.tsv: \"['Gene.symbol'] not in index\"\n",
      "Error processing file GSE67002.top.table.tsv: \"['Gene.symbol'] not in index\"\n",
      "Error processing file GSE67078.top.table (1).tsv: \"['Gene.symbol'] not in index\"\n",
      "Error processing file GSE67078.top.table.tsv: \"['Gene.symbol'] not in index\"\n",
      "Error processing file GSE71542.top.table.tsv: \"['Gene.symbol'] not in index\"\n",
      "Error processing file GSE71546.top.table.tsv: \"['Gene.symbol'] not in index\"\n",
      "Error processing file GSE71547.top.table.tsv: \"['Gene.symbol'] not in index\"\n",
      "Error processing file GSE71549.top.table 1.tsv: \"['Gene.symbol'] not in index\"\n",
      "Error processing file GSE71549.top.table.tsv: \"['Gene.symbol'] not in index\"\n",
      "Error processing file GSE75934.top.table.tsv: \"['Gene.symbol'] not in index\"\n",
      "Error processing file GSE93840.top.table.tsv: \"['Gene.symbol'] not in index\"\n",
      "Compiled data saved to: C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\.venv\\processed_\\Compiled_GEO2R.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Folder containing GEO2R files\n",
    "input_folder = r\"C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\.venv\\datasets for aflatoxinb1\"  # Replace with the actual folder path containing GEO2R files\n",
    "output_file = r\"C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\.venv\\processed_\\Compiled_GEO2R.csv\"  # Replace with the desired output file path\n",
    "\n",
    "# Define the required columns\n",
    "required_columns = ['ID', 'adj.P.Val', 'P.Value','Gene.symbol']\n",
    "\n",
    "# Initialize an empty DataFrame to store compiled data\n",
    "compiled_data = pd.DataFrame(columns=required_columns)\n",
    "\n",
    "# Iterate through all files in the folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith('.tsv'):  # Process only TSV files\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "        \n",
    "        # Read the GEO2R file\n",
    "        try:\n",
    "            data = pd.read_csv(file_path, sep='\\t')\n",
    "            \n",
    "            # Select only the required columns (if they exist in the file)\n",
    "            data = data[required_columns]\n",
    "            \n",
    "            # Append the data to the compiled DataFrame\n",
    "            compiled_data = pd.concat([compiled_data, data], ignore_index=True)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {filename}: {e}\")\n",
    "\n",
    "# Save the compiled data to a CSV file\n",
    "compiled_data.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Compiled data saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data saved to: C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\.venv\\processed_\\Preprocessed_CTD_Data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agk78\\AppData\\Local\\Temp\\ipykernel_5008\\3089844691.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_ctd_data['Normalized Inference Score'] = (filtered_ctd_data['Inference Score'] - min_score) / (max_score - min_score)\n"
     ]
    }
   ],
   "source": [
    "# Load required libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CTD dataset\n",
    "file_path = r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\.venv\\no1 datasets of aflatoxin b1\\CTD_D016604_diseases_20241212062811.tsv'\n",
    "ctd_data = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# Step 1: Split the 'Inference Network' column into individual gene symbols\n",
    "# Explode the gene list into separate rows\n",
    "ctd_data['Inference Network'] = ctd_data['Inference Network'].str.split('|')\n",
    "exploded_ctd_data = ctd_data.explode('Inference Network')\n",
    "\n",
    "# Step 2: Standardize gene symbols\n",
    "# Assuming GEO2R uses uppercase symbols, convert all gene symbols to uppercase\n",
    "exploded_ctd_data['Inference Network'] = exploded_ctd_data['Inference Network'].str.upper()\n",
    "\n",
    "# Step 3: Filter relevant columns for further analysis\n",
    "# Keeping only necessary columns\n",
    "filtered_ctd_data = exploded_ctd_data[['Chemical Name', 'Disease Name', 'Inference Network', 'Inference Score']]\n",
    "\n",
    "# Step 4: Normalize the 'Inference Score'\n",
    "# Min-Max scaling of the 'Inference Score'\n",
    "min_score = filtered_ctd_data['Inference Score'].min()\n",
    "max_score = filtered_ctd_data['Inference Score'].max()\n",
    "filtered_ctd_data['Normalized Inference Score'] = (filtered_ctd_data['Inference Score'] - min_score) / (max_score - min_score)\n",
    "\n",
    "# Step 5: Save the preprocessed data for comparison with GEO2R\n",
    "output_file_path = r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\.venv\\processed_\\Preprocessed_CTD_Data.csv'\n",
    "filtered_ctd_data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Preprocessed data saved to: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ctd_data.loc[:, 'Normalized Inference Score'] = (\n",
    "    filtered_ctd_data['Inference Score'] - min_score\n",
    ") / (max_score - min_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTD data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace with the actual path to your preprocessed CTD data\n",
    "ctd_file_path = r\"C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\.venv\\processed_\\Preprocessed_CTD_Data1.csv\"\n",
    "ctd_data = pd.read_csv(ctd_file_path)\n",
    "\n",
    "print(\"CTD data loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEO2R DEGs data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Replace with the path to your GEO2R DEGs file\n",
    "geo2r_file_path = r\"C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\.venv\\processed_\\Compiled_GEO2R.csv\"\n",
    "geo2r_data = pd.read_csv(geo2r_file_path)\n",
    "\n",
    "print(\"GEO2R DEGs data loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column renamed and data saved to: C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\.venv\\processed_\\Preprocessed_CTD_Data1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "file_path = r\"C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\.venv\\processed_\\Preprocessed_CTD_Data.csv\"  # Replace with the path to your CSV file\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Rename the column\n",
    "data.rename(columns={\"Inference Network\": \"Gene.symbol\"}, inplace=True)\n",
    "\n",
    "# Save the updated DataFrame back to the CSV\n",
    "output_file_path =r\"C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\.venv\\processed_\\Preprocessed_CTD_Data1.csv\"  # Replace with the desired output path\n",
    "data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Column renamed and data saved to: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEO2R Dataset Head:\n",
      "             ID  adj.P.Val       P.Value Gene.symbol\n",
      "0   A_23_P97906    0.00109  7.660000e-08       NT5C2\n",
      "1   A_24_P12932    0.00382  5.360000e-07      MRPS16\n",
      "2   A_32_P18251    0.00481  1.110000e-06      FUNDC2\n",
      "3  A_23_P164047    0.00481  1.350000e-06         MMD\n",
      "4  A_23_P205997    0.00516  2.050000e-06       APH1B\n",
      "\n",
      "CTD Dataset Head:\n",
      "  Chemical Name               Disease Name Gene.symbol  Inference Score  \\\n",
      "0  Aflatoxin B1  Carcinoma, Hepatocellular         A2M           312.89   \n",
      "1  Aflatoxin B1  Carcinoma, Hepatocellular       AADAT           312.89   \n",
      "2  Aflatoxin B1  Carcinoma, Hepatocellular       ABCB1           312.89   \n",
      "3  Aflatoxin B1  Carcinoma, Hepatocellular       ABCB4           312.89   \n",
      "4  Aflatoxin B1  Carcinoma, Hepatocellular       ACACA           312.89   \n",
      "\n",
      "   Normalized Inference Score  \n",
      "0                    0.501128  \n",
      "1                    0.501128  \n",
      "2                    0.501128  \n",
      "3                    0.501128  \n",
      "4                    0.501128  \n",
      "Merged data saved to: path_to_output_merged_file.csv\n",
      "\n",
      "Number of overlapping genes: 5433\n",
      "Number of unique genes in GEO2R: 14014\n",
      "Number of unique genes in CTD: 395\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load GEO2R and CTD datasets\n",
    "geo2r_path = r\"C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\.venv\\processed_\\Compiled_GEO2R.csv\"  # Replace with your GEO2R file path\n",
    "ctd_path = r\"C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\.venv\\processed_\\Preprocessed_CTD_Data1.csv\"      # Replace with your CTD file path\n",
    "\n",
    "geo2r_data = pd.read_csv(geo2r_path)\n",
    "ctd_data = pd.read_csv(ctd_path)\n",
    "\n",
    "# Step 2: Inspect the datasets (Optional)\n",
    "print(\"GEO2R Dataset Head:\")\n",
    "print(geo2r_data.head())\n",
    "print(\"\\nCTD Dataset Head:\")\n",
    "print(ctd_data.head())\n",
    "\n",
    "# Step 3: Rename relevant columns for consistency\n",
    "ctd_data.rename(columns={\"Inference Network\": \"Gene.symbol\"}, inplace=True)\n",
    "\n",
    "# Step 4: Merge datasets (Outer Join on 'Gene.symbol')\n",
    "merged_data = pd.merge(geo2r_data, ctd_data, on=\"Gene.symbol\", how=\"outer\")\n",
    "\n",
    "# Step 5: Save merged dataset\n",
    "output_file_path = \"path_to_output_merged_file.csv\"  # Replace with your desired output path\n",
    "merged_data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Merged data saved to: {output_file_path}\")\n",
    "\n",
    "# Step 6: Analyze the merged dataset\n",
    "# Example Analysis: Check for overlapping genes\n",
    "geo2r_genes = set(geo2r_data['Gene.symbol'].dropna())\n",
    "ctd_genes = set(ctd_data['Gene.symbol'].dropna())\n",
    "\n",
    "overlapping_genes = geo2r_genes.intersection(ctd_genes)\n",
    "unique_to_geo2r = geo2r_genes - ctd_genes\n",
    "unique_to_ctd = ctd_genes - geo2r_genes\n",
    "\n",
    "print(f\"\\nNumber of overlapping genes: {len(overlapping_genes)}\")\n",
    "print(f\"Number of unique genes in GEO2R: {len(unique_to_geo2r)}\")\n",
    "print(f\"Number of unique genes in CTD: {len(unique_to_ctd)}\")\n",
    "\n",
    "# Example Visualization (Optional, Requires matplotlib and seaborn)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot overlapping genes\n",
    "venn_labels = {\n",
    "    \"unique_to_geo2r\": len(unique_to_geo2r),\n",
    "    \"unique_to_ctd\": len(unique_to_ctd),\n",
    "    \"overlapping_genes\": len(overlapping_genes),\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.bar(venn_labels.keys(), venn_labels.values(), color=['blue', 'orange', 'green'])\n",
    "plt.xlabel(\"Gene Overlap Categories\")\n",
    "plt.ylabel(\"Number of Genes\")\n",
    "plt.title(\"Overlap Between GEO2R and CTD Datasets\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Data (first 5 rows):\n",
      "            ID     adj.P.Val       P.Value Gene.symbol Chemical Name  \\\n",
      "0  A_23_P38816  6.723000e-01  4.310000e-01        A1BG  Aflatoxin B1   \n",
      "1  A_23_P38816  6.723000e-01  4.310000e-01        A1BG  Aflatoxin B1   \n",
      "2        25737  3.350000e-12  6.110000e-15        A1BG  Aflatoxin B1   \n",
      "3        25737  3.350000e-12  6.110000e-15        A1BG  Aflatoxin B1   \n",
      "8         7999  3.820000e-01  2.580000e-01         A2M  Aflatoxin B1   \n",
      "\n",
      "                Disease Name  Inference Score  Normalized Inference Score  \\\n",
      "0               Hepatomegaly         0.018334                    0.018334   \n",
      "1              Schizophrenia         0.109828                    0.109828   \n",
      "2               Hepatomegaly         0.018334                    0.018334   \n",
      "3              Schizophrenia         0.109828                    0.109828   \n",
      "8  Carcinoma, Hepatocellular         0.501128                    0.501128   \n",
      "\n",
      "  Toxicity_Level  \n",
      "0         Medium  \n",
      "1           High  \n",
      "2         Medium  \n",
      "3           High  \n",
      "8           High  \n",
      "\n",
      "Distribution of Toxicity Levels:\n",
      "Toxicity_Level\n",
      "Low       34093\n",
      "High      33742\n",
      "Medium    33740\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the dataset\n",
    "file_path =r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\.venv\\path_to_output_merged_file.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Step 1: Handle Missing Data\n",
    "# Remove rows where critical columns have missing values\n",
    "cleaned_data = data.dropna(subset=['Gene.symbol', 'Chemical Name', 'Disease Name', 'Inference Score', 'Normalized Inference Score']).copy()\n",
    "\n",
    "# Step 2: Derive a Target Variable\n",
    "# Categorize 'Normalized Inference Score' into 'low', 'medium', and 'high'\n",
    "cleaned_data.loc[:, 'Toxicity_Level'] = pd.qcut(\n",
    "    cleaned_data['Normalized Inference Score'],\n",
    "    q=3,  # Divide into 3 categories\n",
    "    labels=['Low', 'Medium', 'High']\n",
    ")\n",
    "\n",
    "# Step 3: Normalize Numerical Features\n",
    "# Normalize 'Inference Score' and 'Normalized Inference Score'\n",
    "scaler = MinMaxScaler()\n",
    "cleaned_data[['Inference Score', 'Normalized Inference Score']] = scaler.fit_transform(\n",
    "    cleaned_data[['Inference Score', 'Normalized Inference Score']]\n",
    ")\n",
    "\n",
    "# Display preprocessing results\n",
    "print(\"Cleaned Data (first 5 rows):\")\n",
    "print(cleaned_data.head())\n",
    "\n",
    "print(\"\\nDistribution of Toxicity Levels:\")\n",
    "print(cleaned_data['Toxicity_Level'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (60945, 10389)\n",
      "Validation set size: (20315, 10389)\n",
      "Test set size: (20315, 10389)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Assume `cleaned_data` is already prepared from previous steps\n",
    "\n",
    "# Step 1: One-Hot Encoding for Categorical Variables\n",
    "categorical_columns = ['Chemical Name', 'Disease Name', 'Gene.symbol']\n",
    "encoded_data = pd.get_dummies(cleaned_data, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Step 2: Feature Engineering\n",
    "# Example: Interaction term between 'Inference Score' and 'Normalized Inference Score'\n",
    "encoded_data['Interaction_Term'] = (\n",
    "    encoded_data['Inference Score'] * encoded_data['Normalized Inference Score']\n",
    ")\n",
    "\n",
    "# Step 3: Split Data\n",
    "# Separate features (X) and target variable (y)\n",
    "X = encoded_data.drop(columns=['Toxicity_Level', 'ID'])  # Drop non-predictive columns\n",
    "y = encoded_data['Toxicity_Level']\n",
    "\n",
    "# Convert target variable to numerical format\n",
    "y_encoded = y.map({'Low': 0, 'Medium': 1, 'High': 2})\n",
    "\n",
    "# Split data into training, validation, and testing sets (60-20-20 split)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y_encoded, test_size=0.4, random_state=42, stratify=y_encoded)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Summary of splits\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Validation set size:\", X_val.shape)\n",
    "print(\"Test set size:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets saved successfully:\n",
      "- Training set: X_train.csv, y_train.csv\n",
      "- Validation set: X_val.csv, y_val.csv\n",
      "- Test set: X_test.csv, y_test.csv\n"
     ]
    }
   ],
   "source": [
    "# Save training, validation, and test datasets to CSV files\n",
    "\n",
    "# Save features and target for the training set\n",
    "X_train.to_csv(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\.venv\\processed_\\X_train.csv', index=False)\n",
    "y_train.to_csv(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\.venv\\processed_\\y_train.csv', index=False)\n",
    "\n",
    "# Save features and target for the validation set\n",
    "X_val.to_csv(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\.venv\\processed_\\X_val.csv', index=False)\n",
    "y_val.to_csv(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\.venv\\processed_\\y_val.csv', index=False)\n",
    "\n",
    "# Save features and target for the test set\n",
    "X_test.to_csv(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\.venv\\processed_\\X_test.csv', index=False)\n",
    "y_test.to_csv(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\.venv\\processed_\\y_test.csv', index=False)\n",
    "\n",
    "print(\"Datasets saved successfully:\")\n",
    "print(\"- Training set: X_train.csv, y_train.csv\")\n",
    "print(\"- Validation set: X_val.csv, y_val.csv\")\n",
    "print(\"- Test set: X_test.csv, y_test.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code for combined datasets data 1 and data 2 donot run the code the file is already be saved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "file_1_path = r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\cleaned_data.csv'  # Update to the actual path\n",
    "file_2_path = r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\.venv\\no1 datasets of aflatoxin b1\\CTD_D016604_ixns_20241212063652.csv'  # Update to the actual path\n",
    "\n",
    "data_1 = pd.read_csv(file_1_path)\n",
    "data_2 = pd.read_csv(file_2_path)\n",
    "\n",
    "# Ensure column names match for merging\n",
    "data_2.rename(columns={'Gene Symbol': 'Gene.symbol', 'Chemical Name': 'Chemical Name'}, inplace=True)\n",
    "\n",
    "# Perform an inner join on common columns: 'Gene.symbol' and 'Chemical Name'\n",
    "combined_data = pd.merge(data_1, data_2, on=['Gene.symbol', 'Chemical Name'], how='inner')\n",
    "\n",
    "# Save the combined dataset to a file\n",
    "combined_file_path = r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\.venv\\processed_\\combined_dataafl.csv'  # Update to the desired save path\n",
    "combined_data.to_csv(combined_file_path, index=False)\n",
    "\n",
    "# Display some details about the combined dataset\n",
    "print(f\"Combined data has {combined_data.shape[0]} rows and {combined_data.shape[1]} columns.\")\n",
    "print(f\"Combined dataset saved to: {combined_file_path}\")\n",
    "print(combined_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse datasets saved successfully:\n",
      "- Training set: X_train_sparse.pkl, y_train.pkl\n",
      "- Validation set: X_val_sparse.pkl, y_val.pkl\n",
      "- Test set: X_test_sparse.pkl, y_test.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_columns = ['Chemical Name', 'Gene.symbol', 'Disease Name', 'Interaction Actions']\n",
    "numerical_columns = ['adj.P.Val', 'P.Value', 'Inference Score', 'Normalized Inference Score', 'Reference Count', 'Organism Count']\n",
    "\n",
    "# Initialize sparse one-hot encoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=True)\n",
    "\n",
    "# Fit and transform the categorical columns\n",
    "encoded_sparse = encoder.fit_transform(data[categorical_columns])\n",
    "\n",
    "# Combine sparse encoded features with numerical features\n",
    "X_sparse = hstack([encoded_sparse, data[numerical_columns]])\n",
    "\n",
    "# Convert the target variable into numerical format\n",
    "y = data['Toxicity_Level'].map({'Low': 0, 'Medium': 1, 'High': 2})\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_sparse, X_temp_sparse, y_train, y_temp = train_test_split(\n",
    "    X_sparse, y, test_size=0.4, random_state=42, stratify=y)\n",
    "\n",
    "X_val_sparse, X_test_sparse, y_val, y_test = train_test_split(\n",
    "    X_temp_sparse, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Save the sparse datasets to files\n",
    "import joblib\n",
    "joblib.dump(X_train_sparse,r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\X_train_sparse.pkl')\n",
    "joblib.dump(X_val_sparse,r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\X_val_sparse.pkl')\n",
    "joblib.dump(X_test_sparse,r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\X_test_sparse.pkl')\n",
    "joblib.dump(y_train,r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\y_train.pkl')\n",
    "joblib.dump(y_val,r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\y_val.pkl')\n",
    "joblib.dump(y_test,r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\y_test.pkl')\n",
    "\n",
    "print(\"Sparse datasets saved successfully:\")\n",
    "print(\"- Training set: X_train_sparse.pkl, y_train.pkl\")\n",
    "print(\"- Validation set: X_val_sparse.pkl, y_val.pkl\")\n",
    "print(\"- Test set: X_test_sparse.pkl, y_test.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       0.99      1.00      1.00     19864\n",
      "      Medium       1.00      0.99      1.00     20489\n",
      "        High       1.00      1.00      1.00     18809\n",
      "\n",
      "    accuracy                           1.00     59162\n",
      "   macro avg       1.00      1.00      1.00     59162\n",
      "weighted avg       1.00      1.00      1.00     59162\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19790    74     0]\n",
      " [  108 20381     0]\n",
      " [    0     0 18809]]\n",
      "\n",
      "Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       0.99      1.00      0.99     19864\n",
      "      Medium       1.00      0.99      0.99     20489\n",
      "        High       1.00      1.00      1.00     18810\n",
      "\n",
      "    accuracy                           1.00     59163\n",
      "   macro avg       1.00      1.00      1.00     59163\n",
      "weighted avg       1.00      1.00      1.00     59163\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19780    84     0]\n",
      " [  129 20360     0]\n",
      " [    0     0 18810]]\n",
      "Model saved successfully: logistic_regression_model_imputed.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# Load the sparse datasets\n",
    "X_train_sparse = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\X_train_sparse.pkl')\n",
    "X_val_sparse = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\X_val_sparse.pkl')\n",
    "X_test_sparse = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\X_test_sparse.pkl')\n",
    "y_train = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\y_train.pkl')\n",
    "y_val = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\y_val.pkl')\n",
    "y_test = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\y_test.pkl')\n",
    "\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_sparse = imputer.fit_transform(X_train_sparse)\n",
    "X_val_sparse = imputer.transform(X_val_sparse)\n",
    "X_test_sparse = imputer.transform(X_test_sparse)\n",
    "\n",
    "# Initialize and train the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train_sparse, y_train)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "y_val_pred = model.predict(X_val_sparse)\n",
    "\n",
    "# Validation metrics\n",
    "print(\"Validation Set Performance:\")\n",
    "print(classification_report(y_val, y_val_pred, target_names=['Low', 'Medium', 'High']))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred))\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_test_pred = model.predict(X_test_sparse)\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=['Low', 'Medium', 'High']))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\logistic_regression_model_imputed.pkl')\n",
    "print(\"Model saved successfully: logistic_regression_model_imputed.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID     adj.P.Val       P.Value Gene.symbol Chemical Name  \\\n",
      "0  A_23_P38816  6.723000e-01  4.310000e-01        A1BG  Aflatoxin B1   \n",
      "1  A_23_P38816  6.723000e-01  4.310000e-01        A1BG  Aflatoxin B1   \n",
      "2  A_23_P38816  6.723000e-01  4.310000e-01        A1BG  Aflatoxin B1   \n",
      "3  A_23_P38816  6.723000e-01  4.310000e-01        A1BG  Aflatoxin B1   \n",
      "4        25737  3.350000e-12  6.110000e-15        A1BG  Aflatoxin B1   \n",
      "\n",
      "    Disease Name  Inference Score  Normalized Inference Score Toxicity_Level  \\\n",
      "0   Hepatomegaly         0.018334                    0.018334         Medium   \n",
      "1   Hepatomegaly         0.018334                    0.018334         Medium   \n",
      "2  Schizophrenia         0.109828                    0.109828           High   \n",
      "3  Schizophrenia         0.109828                    0.109828           High   \n",
      "4   Hepatomegaly         0.018334                    0.018334         Medium   \n",
      "\n",
      "  Chemical ID     CAS RN  Gene ID  \\\n",
      "0     D016604  1162-65-8        1   \n",
      "1     D016604  1162-65-8        1   \n",
      "2     D016604  1162-65-8        1   \n",
      "3     D016604  1162-65-8        1   \n",
      "4     D016604  1162-65-8        1   \n",
      "\n",
      "                                         Interaction   Interaction Actions  \\\n",
      "0  Aflatoxin B1 results in decreased expression o...  decreases^expression   \n",
      "1  Aflatoxin B1 results in increased expression o...  increases^expression   \n",
      "2  Aflatoxin B1 results in decreased expression o...  decreases^expression   \n",
      "3  Aflatoxin B1 results in increased expression o...  increases^expression   \n",
      "4  Aflatoxin B1 results in decreased expression o...  decreases^expression   \n",
      "\n",
      "   Reference Count  Organism Count  \n",
      "0                2               1  \n",
      "1                2               1  \n",
      "2                2               1  \n",
      "3                2               1  \n",
      "4                2               1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the combined dataset\n",
    "file_path = r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\.venv\\processed_\\combined_dataafl.csv'  # Update this path if needed\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to confirm\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the original categorical and numerical columns\n",
    "categorical_columns = ['Chemical Name', 'Gene.symbol', 'Disease Name', 'Interaction Actions']\n",
    "numerical_columns = ['adj.P.Val', 'P.Value', 'Inference Score', \n",
    "                     'Normalized Inference Score', 'Reference Count', 'Organism Count']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Initialize the encoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=True)\n",
    "\n",
    "# Fit the encoder on the categorical columns\n",
    "encoder.fit(data[categorical_columns])\n",
    "\n",
    "# Generate feature names\n",
    "feature_names = encoder.get_feature_names_out(categorical_columns).tolist() + numerical_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Important Features:\n",
      "                                              Feature  Importance\n",
      "10482                      Normalized Inference Score   15.037374\n",
      "10481                                 Inference Score   15.037374\n",
      "6702     Disease Name_Cell Transformation, Neoplastic    3.462473\n",
      "9130   Disease Name_Non-alcoholic Fatty Liver Disease    3.343422\n",
      "1                          Chemical Name_Aflatoxin B1    3.297589\n",
      "6613            Disease Name_Carcinoma, Squamous Cell    3.233645\n",
      "7191              Disease Name_Disease Models, Animal    3.214551\n",
      "10227          Disease Name_Urinary Bladder Neoplasms    3.170903\n",
      "6050                   Disease Name_Alzheimer Disease    3.065019\n",
      "6842                   Disease Name_Colonic Neoplasms    2.900891\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get model coefficients\n",
    "coefficients = model.coef_\n",
    "\n",
    "# Convert to absolute importance for all classes\n",
    "importance = np.abs(coefficients).mean(axis=0)\n",
    "\n",
    "# Create a DataFrame for feature importance\n",
    "feature_importance = pd.DataFrame({'Feature': feature_names, 'Importance': importance})\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display top 10 features\n",
    "print(\"Top 10 Important Features:\")\n",
    "print(feature_importance.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path\\to\\filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Define the original categorical columns\n",
    "categorical_columns = ['Chemical Name', 'Gene.symbol', 'Disease Name', 'Interaction Actions']\n",
    "\n",
    "# Recreate the encoder with the same settings\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=True)\n",
    "\n",
    "# Fit the encoder on the original categorical columns from the dataset\n",
    "encoder.fit(data[categorical_columns])\n",
    "\n",
    "# Combine feature names\n",
    "feature_names = encoder.get_feature_names_out(categorical_columns).tolist() + numerical_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Important Features:\n",
      "                                              Feature  Importance\n",
      "10482                      Normalized Inference Score   15.037374\n",
      "10481                                 Inference Score   15.037374\n",
      "6702     Disease Name_Cell Transformation, Neoplastic    3.462473\n",
      "9130   Disease Name_Non-alcoholic Fatty Liver Disease    3.343422\n",
      "1                          Chemical Name_Aflatoxin B1    3.297589\n",
      "6613            Disease Name_Carcinoma, Squamous Cell    3.233645\n",
      "7191              Disease Name_Disease Models, Animal    3.214551\n",
      "10227          Disease Name_Urinary Bladder Neoplasms    3.170903\n",
      "6050                   Disease Name_Alzheimer Disease    3.065019\n",
      "6842                   Disease Name_Colonic Neoplasms    2.900891\n",
      "Feature importance saved to: feature_importance.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get feature importance from model coefficients\n",
    "feature_names = encoder.get_feature_names_out(categorical_columns).tolist() + numerical_columns\n",
    "coefficients = model.coef_\n",
    "\n",
    "# Convert to absolute importance for all classes\n",
    "importance = np.abs(coefficients).mean(axis=0)\n",
    "\n",
    "# Create a DataFrame for feature importance\n",
    "feature_importance = pd.DataFrame({'Feature': feature_names, 'Importance': importance})\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display top 10 most important features\n",
    "print(\"Top 10 Important Features:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Optional: Save feature importance to a file\n",
    "feature_importance.to_csv(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\feature_importance.csv', index=False)\n",
    "print(\"Feature importance saved to: feature_importance.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-Fold Cross-Validation Accuracy Scores: [0.9961688  0.99647858 0.99577429 0.99676029 0.99591515]\n",
      "Mean Accuracy: 0.996219420408495\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "cv_scores = cross_val_score(model, X_train_sparse, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "print(\"5-Fold Cross-Validation Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Accuracy:\", np.mean(cv_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN - Validation Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     19864\n",
      "           1       0.98      0.98      0.98     20489\n",
      "           2       0.99      0.99      0.99     18809\n",
      "\n",
      "    accuracy                           0.98     59162\n",
      "   macro avg       0.98      0.98      0.98     59162\n",
      "weighted avg       0.98      0.98      0.98     59162\n",
      "\n",
      "[[19512   279    73]\n",
      " [  369 20075    45]\n",
      " [   50   117 18642]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# Load the sparse datasets\n",
    "X_train_sparse = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\X_train_sparse.pkl')\n",
    "X_val_sparse = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\X_val_sparse.pkl')\n",
    "X_test_sparse = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\X_test_sparse.pkl')\n",
    "y_train = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\y_train.pkl')\n",
    "y_val = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\y_val.pkl')\n",
    "y_test = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\y_test.pkl')\n",
    "\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_sparse = imputer.fit_transform(X_train_sparse)\n",
    "X_val_sparse = imputer.transform(X_val_sparse)\n",
    "X_test_sparse = imputer.transform(X_test_sparse)\n",
    "# Train k-NN\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train_sparse, y_train)\n",
    "\n",
    "# Evaluate k-NN\n",
    "y_val_pred_knn = knn_model.predict(X_val_sparse)\n",
    "print(\"k-NN - Validation Performance\")\n",
    "print(classification_report(y_val, y_val_pred_knn))\n",
    "print(confusion_matrix(y_val, y_val_pred_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k-value: {'n_neighbors': 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {'n_neighbors': [3, 5, 7, 9]}\n",
    "\n",
    "# Perform Grid Search\n",
    "knn_grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=3, scoring='accuracy')\n",
    "knn_grid.fit(X_train_sparse, y_train)\n",
    "\n",
    "# Best k-value\n",
    "print(f\"Best k-value: {knn_grid.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN (k=3) - Validation Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98     19864\n",
      "           1       0.98      0.98      0.98     20489\n",
      "           2       1.00      0.99      0.99     18809\n",
      "\n",
      "    accuracy                           0.99     59162\n",
      "   macro avg       0.99      0.99      0.99     59162\n",
      "weighted avg       0.99      0.99      0.99     59162\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19580   236    48]\n",
      " [  315 20129    45]\n",
      " [   40    81 18688]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Initialize k-NN with the best k-value\n",
    "knn_best = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train k-NN\n",
    "knn_best.fit(X_train_sparse, y_train)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "y_val_pred_knn_best = knn_best.predict(X_val_sparse)\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"k-NN (k=3) - Validation Performance\")\n",
    "print(classification_report(y_val, y_val_pred_knn_best))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred_knn_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the saved k-NN model\n",
    "knn_model = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\knn_best_model.pkl')\n",
    "\n",
    "print(\"k-NN model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data loaded successfully!\n",
      "X_test_sparse shape: (59163, 10485)\n",
      "y_test shape: (59163,)\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the preprocessed test feature data (X_test_sparse)\n",
    "X_test_sparse = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\X_test_sparse.pkl')\n",
    "\n",
    "# Load the test target labels (y_test)\n",
    "y_test = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\y_test.pkl')\n",
    "\n",
    "print(\"Test data loaded successfully!\")\n",
    "print(f\"X_test_sparse shape: {X_test_sparse.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values imputed successfully!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Initialize the imputer (mean strategy)\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Impute missing values in sparse matrix\n",
    "X_test_sparse_imputed = imputer.fit_transform(X_test_sparse)\n",
    "\n",
    "# Ensure it's still in sparse format\n",
    "X_test_sparse_imputed = csr_matrix(X_test_sparse_imputed)\n",
    "\n",
    "print(\"Missing values imputed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with NaNs removed. Remaining rows: 58764\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Convert sparse matrix to dense to handle NaNs\n",
    "X_test_dense = X_test_sparse.toarray()\n",
    "\n",
    "# Identify rows without NaNs\n",
    "non_nan_indices = ~np.isnan(X_test_dense).any(axis=1)\n",
    "\n",
    "# Filter out rows with NaNs and convert back to sparse format\n",
    "X_test_sparse_cleaned = csr_matrix(X_test_dense[non_nan_indices])\n",
    "\n",
    "# Ensure corresponding labels are also filtered\n",
    "y_test_cleaned = y_test[non_nan_indices]\n",
    "\n",
    "print(f\"Rows with NaNs removed. Remaining rows: {X_test_sparse_cleaned.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN (k=3) - Test Performance (After Removing NaNs)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     19763\n",
      "           1       0.99      0.98      0.98     20334\n",
      "           2       0.99      0.99      0.99     18667\n",
      "\n",
      "    accuracy                           0.99     58764\n",
      "   macro avg       0.99      0.99      0.99     58764\n",
      "weighted avg       0.99      0.99      0.99     58764\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19516   183    64]\n",
      " [  292 19996    46]\n",
      " [   36    92 18539]]\n"
     ]
    }
   ],
   "source": [
    "# Predict using cleaned data\n",
    "y_test_pred_knn = knn_model.predict(X_test_sparse_cleaned)\n",
    "\n",
    "# Evaluate performance\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"k-NN (k=3) - Test Performance (After Removing NaNs)\")\n",
    "print(classification_report(y_test_cleaned, y_test_pred_knn))\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_cleaned, y_test_pred_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized k-NN model saved successfully: knn_best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the optimized k-NN model\n",
    "joblib.dump(knn_best,r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\knn_best_model.pkl')\n",
    "print(\"Optimized k-NN model saved successfully: knn_best_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:13:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - Validation Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19864\n",
      "           1       1.00      1.00      1.00     20489\n",
      "           2       1.00      1.00      1.00     18809\n",
      "\n",
      "    accuracy                           1.00     59162\n",
      "   macro avg       1.00      1.00      1.00     59162\n",
      "weighted avg       1.00      1.00      1.00     59162\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19864     0     0]\n",
      " [    0 20489     0]\n",
      " [    0     0 18809]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# Load the sparse datasets\n",
    "X_train_sparse = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\X_train_sparse.pkl')\n",
    "X_val_sparse = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\X_val_sparse.pkl')\n",
    "X_test_sparse = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\X_test_sparse.pkl')\n",
    "y_train = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\y_train.pkl')\n",
    "y_val = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\y_val.pkl')\n",
    "y_test = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\y_test.pkl')\n",
    "\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_sparse = imputer.fit_transform(X_train_sparse)\n",
    "X_val_sparse = imputer.transform(X_val_sparse)\n",
    "X_test_sparse = imputer.transform(X_test_sparse)\n",
    "\n",
    "# Initialize and train XGBoost\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "xgb_model.fit(X_train_sparse, y_train)\n",
    "\n",
    "# Evaluate XGBoost\n",
    "y_val_pred_xgb = xgb_model.predict(X_val_sparse)\n",
    "\n",
    "# Print results\n",
    "print(\"XGBoost - Validation Performance\")\n",
    "print(classification_report(y_val, y_val_pred_xgb))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - Test Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19864\n",
      "           1       1.00      1.00      1.00     20489\n",
      "           2       1.00      1.00      1.00     18810\n",
      "\n",
      "    accuracy                           1.00     59163\n",
      "   macro avg       1.00      1.00      1.00     59163\n",
      "weighted avg       1.00      1.00      1.00     59163\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19864     0     0]\n",
      " [    0 20489     0]\n",
      " [    0     0 18810]]\n"
     ]
    }
   ],
   "source": [
    "y_test_pred_xgb = xgb_model.predict(X_test_sparse)\n",
    "\n",
    "print(\"XGBoost - Test Performance\")\n",
    "print(classification_report(y_test, y_test_pred_xgb))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost model saved successfully: xgboost_best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained XGBoost model\n",
    "joblib.dump(xgb_model,r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\xgboost_best_model.pkl')\n",
    "\n",
    "print(\"XGBoost model saved successfully: xgboost_best_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.640535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4522\n",
      "[LightGBM] [Info] Number of data points in the train set: 177486, number of used features: 1758\n",
      "[LightGBM] [Info] Start training from score -1.091370\n",
      "[LightGBM] [Info] Start training from score -1.060391\n",
      "[LightGBM] [Info] Start training from score -1.145944\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM - Validation Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19864\n",
      "           1       1.00      1.00      1.00     20489\n",
      "           2       1.00      1.00      1.00     18809\n",
      "\n",
      "    accuracy                           1.00     59162\n",
      "   macro avg       1.00      1.00      1.00     59162\n",
      "weighted avg       1.00      1.00      1.00     59162\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19864     0     0]\n",
      " [    0 20489     0]\n",
      " [    0     0 18809]]\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# Load the sparse datasets\n",
    "X_train_sparse = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\X_train_sparse.pkl')\n",
    "X_val_sparse = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\X_val_sparse.pkl')\n",
    "X_test_sparse = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\X_test_sparse.pkl')\n",
    "y_train = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\y_train.pkl')\n",
    "y_val = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\y_val.pkl')\n",
    "y_test = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\y_test.pkl')\n",
    "\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_sparse = imputer.fit_transform(X_train_sparse)\n",
    "X_val_sparse = imputer.transform(X_val_sparse)\n",
    "X_test_sparse = imputer.transform(X_test_sparse)\n",
    "\n",
    "# Initialize and train LightGBM\n",
    "lgbm_model = LGBMClassifier(random_state=42)\n",
    "lgbm_model.fit(X_train_sparse, y_train)\n",
    "\n",
    "# Evaluate LightGBM\n",
    "y_val_pred_lgbm = lgbm_model.predict(X_val_sparse)\n",
    "\n",
    "# Print results\n",
    "print(\"LightGBM - Validation Performance\")\n",
    "print(classification_report(y_val, y_val_pred_lgbm))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred_lgbm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM - Test Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19864\n",
      "           1       1.00      1.00      1.00     20489\n",
      "           2       1.00      1.00      1.00     18810\n",
      "\n",
      "    accuracy                           1.00     59163\n",
      "   macro avg       1.00      1.00      1.00     59163\n",
      "weighted avg       1.00      1.00      1.00     59163\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19864     0     0]\n",
      " [    0 20489     0]\n",
      " [    0     0 18810]]\n"
     ]
    }
   ],
   "source": [
    "y_test_pred_lgbm = lgbm_model.predict(X_test_sparse)\n",
    "\n",
    "print(\"LightGBM - Test Performance\")\n",
    "print(classification_report(y_test, y_test_pred_lgbm))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_lgbm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM model saved successfully: lightgbm_best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained LightGBM model\n",
    "joblib.dump(lgbm_model,r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\lightgbm_best_model.pkl')\n",
    "\n",
    "print(\"LightGBM model saved successfully: lightgbm_best_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Validation Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19864\n",
      "           1       1.00      1.00      1.00     20489\n",
      "           2       1.00      1.00      1.00     18809\n",
      "\n",
      "    accuracy                           1.00     59162\n",
      "   macro avg       1.00      1.00      1.00     59162\n",
      "weighted avg       1.00      1.00      1.00     59162\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19864     0     0]\n",
      " [    0 20489     0]\n",
      " [    0     0 18809]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# Load the sparse datasets\n",
    "X_train_sparse = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\X_train_sparse.pkl')\n",
    "X_val_sparse = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\X_val_sparse.pkl')\n",
    "X_test_sparse = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\X_test_sparse.pkl')\n",
    "y_train = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\y_train.pkl')\n",
    "y_val = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\y_val.pkl')\n",
    "y_test = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\y_test.pkl')\n",
    "\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_sparse = imputer.fit_transform(X_train_sparse)\n",
    "X_val_sparse = imputer.transform(X_val_sparse)\n",
    "X_test_sparse = imputer.transform(X_test_sparse)\n",
    "# Initialize and train Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_sparse, y_train)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "y_val_pred_rf = rf_model.predict(X_val_sparse)\n",
    "\n",
    "# Print results\n",
    "print(\"Random Forest - Validation Performance\")\n",
    "print(classification_report(y_val, y_val_pred_rf))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Test Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19864\n",
      "           1       1.00      1.00      1.00     20489\n",
      "           2       1.00      1.00      1.00     18810\n",
      "\n",
      "    accuracy                           1.00     59163\n",
      "   macro avg       1.00      1.00      1.00     59163\n",
      "weighted avg       1.00      1.00      1.00     59163\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19864     0     0]\n",
      " [    0 20489     0]\n",
      " [    0     0 18810]]\n"
     ]
    }
   ],
   "source": [
    "y_test_pred_rf = rf_model.predict(X_test_sparse)\n",
    "\n",
    "print(\"Random Forest - Test Performance\")\n",
    "print(classification_report(y_test, y_test_pred_rf))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model saved successfully: random_forest_best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained Random Forest model\n",
    "joblib.dump(rf_model,r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\random_forest_best_model.pkl')\n",
    "\n",
    "print(\"Random Forest model saved successfully: random_forest_best_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9097917\ttotal: 287ms\tremaining: 2m 23s\n",
      "100:\tlearn: 0.0000734\ttotal: 9.69s\tremaining: 38.3s\n",
      "200:\tlearn: 0.0000115\ttotal: 19s\tremaining: 28.3s\n",
      "300:\tlearn: 0.0000064\ttotal: 28.8s\tremaining: 19s\n",
      "400:\tlearn: 0.0000045\ttotal: 39.1s\tremaining: 9.64s\n",
      "499:\tlearn: 0.0000035\ttotal: 48.6s\tremaining: 0us\n",
      "CatBoost - Validation Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19864\n",
      "           1       1.00      1.00      1.00     20489\n",
      "           2       1.00      1.00      1.00     18809\n",
      "\n",
      "    accuracy                           1.00     59162\n",
      "   macro avg       1.00      1.00      1.00     59162\n",
      "weighted avg       1.00      1.00      1.00     59162\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19864     0     0]\n",
      " [    0 20489     0]\n",
      " [    0     0 18809]]\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# Load the sparse datasets\n",
    "X_train_sparse = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\X_train_sparse.pkl')\n",
    "X_val_sparse = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\X_val_sparse.pkl')\n",
    "X_test_sparse = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\X_test_sparse.pkl')\n",
    "y_train = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\y_train.pkl')\n",
    "y_val = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\y_val.pkl')\n",
    "y_test = joblib.load(r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\y_test.pkl')\n",
    "\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_sparse = imputer.fit_transform(X_train_sparse)\n",
    "X_val_sparse = imputer.transform(X_val_sparse)\n",
    "X_test_sparse = imputer.transform(X_test_sparse)\n",
    "\n",
    "# Train CatBoost\n",
    "cat_model = CatBoostClassifier(iterations=500, depth=6, learning_rate=0.1, verbose=100, random_state=42)\n",
    "cat_model.fit(X_train_sparse, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_val_pred_cat = cat_model.predict(X_val_sparse)\n",
    "\n",
    "print(\"CatBoost - Validation Performance\")\n",
    "print(classification_report(y_val, y_val_pred_cat))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred_cat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost - Test Performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     19864\n",
      "           1       1.00      1.00      1.00     20489\n",
      "           2       1.00      1.00      1.00     18810\n",
      "\n",
      "    accuracy                           1.00     59163\n",
      "   macro avg       1.00      1.00      1.00     59163\n",
      "weighted avg       1.00      1.00      1.00     59163\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19864     0     0]\n",
      " [    0 20489     0]\n",
      " [    0     0 18810]]\n"
     ]
    }
   ],
   "source": [
    "y_test_pred_cat = cat_model.predict(X_test_sparse)\n",
    "\n",
    "print(\"CatBoost - Test Performance\")\n",
    "print(classification_report(y_test, y_test_pred_cat))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_cat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost model saved successfully: catboost_best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained CatBoost model\n",
    "joblib.dump(cat_model,r'C:\\Users\\agk78\\OneDrive\\Desktop\\AFL\\processed_files\\catboost_best_model.pkl')\n",
    "\n",
    "print(\"CatBoost model saved successfully: catboost_best_model.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
